import streamlit as st
import pandas as pd
import numpy as np
import pickle
import faiss
import re
import os
import shutil
import zipfile
from rank_bm25 import BM25Okapi
from sentence_transformers import SentenceTransformer
from huggingface_hub import hf_hub_download

# ============================================
# 1. C·∫§U H√åNH & CSS
# ============================================
st.set_page_config(page_title="H&M AI Shop", page_icon="üõçÔ∏è", layout="wide")

st.markdown("""
<style>
    .main {background-color: #f8f9fa;}
    .stButton>button {width: 100%; border-radius: 5px; font-weight: bold;}
    .block-container {padding-top: 2rem;}
    div[data-testid="stMetricValue"] {font-size: 1.1rem;}
</style>
""", unsafe_allow_html=True)

# ============================================
# 2. H·ªÜ TH·ªêNG T·∫¢I ·∫¢NH T·ª™ DATASET (CACHE)
# ============================================
# üëâ S·ª¨A L·∫†I TH√îNG TIN N√ÄY CHO ƒê√öNG C·ª¶A BRO
DATASET_REPO_ID = "stephenhoang/hm-fashion-images-demo" 
ZIP_FILENAME = "hm_images_50k_optimized.zip" # T√™n file zip bro ƒë√£ up l√™n dataset
LOCAL_IMG_DIR = "/tmp/hm_images_cache" # Th∆∞ m·ª•c t·∫°m tr√™n Space

@st.cache_resource
def setup_image_cache():
    """T·∫£i v√† gi·∫£i n√©n ·∫£nh t·ª´ Hugging Face Dataset (Ch·ªâ ch·∫°y 1 l·∫ßn)"""
    if not os.path.exists(LOCAL_IMG_DIR):
        os.makedirs(LOCAL_IMG_DIR, exist_ok=True)
        try:
            print(" ƒêang t·∫£i kho ·∫£nh t·ª´ Dataset (L·∫ßn ƒë·∫ßu s·∫Ω l√¢u)...")
            zip_path = hf_hub_download(
                repo_id=DATASET_REPO_ID,
                filename=ZIP_FILENAME,
                repo_type="dataset",
                token=os.environ.get("HF_TOKEN")
            )
            
            print(" ƒêang gi·∫£i n√©n...")
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(LOCAL_IMG_DIR)
            print("Kho ·∫£nh ƒë√£ s·∫µn s√†ng!")
            return True
        except Exception as e:
            print(f"‚ùå L·ªói t·∫£i ·∫£nh: {e}")
            return False
    return True

# K√≠ch ho·∫°t h·ªá th·ªëng ·∫£nh
cache_status = setup_image_cache()

# ============================================
# 3. LOAD MODEL & DATA
# ============================================
@st.cache_resource
def load_models():
    MODEL_PATH = "." 
    print("‚è≥ Loading Models & Data...")
    
    # Load DataFrame
    with open(f'{MODEL_PATH}/df_products.pkl', 'rb') as f:
        df = pickle.load(f)
        
    # Load BM25 (X·ª≠ l√Ω n·∫øu thi·∫øu)
    try:
        with open(f'{MODEL_PATH}/bm25_model.pkl', 'rb') as f:
            bm25 = pickle.load(f)
    except:
        bm25 = None
        
    # Load Embeddings
    embeddings = np.load(f'{MODEL_PATH}/sbert_embeddings.npy')
    
    # Load SBERT
    sbert_model = SentenceTransformer('all-MiniLM-L6-v2')
    
    return df, bm25, embeddings, sbert_model

try:
    df, bm25, embeddings, sbert_model = load_models()
    
    # Build FAISS Index
    faiss.normalize_L2(embeddings)
    index = faiss.IndexFlatIP(embeddings.shape[1])
    index.add(embeddings)
    
except Exception as e:
    st.error(f"‚ùå L·ªói load model: {e}")
    st.stop()

# ============================================
# 4. CLASS SEARCH ENGINE & RECOMMENDATION
# ============================================
class ShopSearchEngine:
    def __init__(self, df, bm25, index, sbert_model, embeddings):
        self.df = df
        self.bm25 = bm25
        self.index = index
        self.sbert_model = sbert_model
        self.embeddings = embeddings # L∆∞u embeddings ƒë·ªÉ d√πng cho recommend
        
        self.phrase_synonyms = {
            'running shoes': ['trainers', 'sneakers', 'runners', 'athletic footwear'],
            'summer dress': ['sundress', 'floral dress', 'beachwear'],
            'hoodie': ['sweatshirt', 'hooded top'],
            'denim': ['jeans', 'blue jeans', 'trousers']
        }

    def _min_max_normalize(self, scores):
        min_s, max_s = np.min(scores), np.max(scores)
        if max_s - min_s == 0: return np.zeros_like(scores)
        return (scores - min_s) / (max_s - min_s)
    
    def _expand_query(self, query):
        q_lower = str(query).lower()
        terms = []
        for k, v in self.phrase_synonyms.items():
            if k in q_lower: terms.extend(v)
        if terms: return q_lower + " " + " ".join(list(set(terms)))
        return q_lower

    def search(self, query, top_k=20, alpha=0.5):
        # 1. Expand
        expanded_q = self._expand_query(query)
        
        # 2. Semantic Search
        q_vec = self.sbert_model.encode([query]).astype('float32')
        faiss.normalize_L2(q_vec)
        D, I = self.index.search(q_vec, len(self.df))
        
        sbert_raw = np.zeros(len(self.df))
        sbert_raw[I[0]] = D[0]
        sbert_norm = self._min_max_normalize(sbert_raw)
        
        # 3. Lexical Search
        if self.bm25:
            q_tok = re.sub(r"[^a-z0-9\s]", " ", expanded_q).split()
            bm25_raw = self.bm25.get_scores(q_tok)
            bm25_norm = self._min_max_normalize(bm25_raw)
            final_scores = (alpha * bm25_norm) + ((1 - alpha) * sbert_norm)
        else:
            final_scores = sbert_norm
            bm25_norm = np.zeros(len(self.df))
            
        # 4. Sort & Format
        top_indices = np.argsort(final_scores)[::-1][:top_k]
        results = self.df.iloc[top_indices].copy()
        results['score'] = final_scores[top_indices]
        return results, expanded_q

    def get_related_products(self, article_id, top_k=5):
        """G·ª£i √Ω s·∫£n ph·∫©m t∆∞∆°ng t·ª± d·ª±a tr√™n vector"""
        try:
            # T√¨m index c·ªßa s·∫£n ph·∫©m trong dataframe
            idx = self.df[self.df['article_id'].astype(str) == str(article_id)].index[0]
            
            # L·∫•y vector c·ªßa n√≥
            target_vec = self.embeddings[idx].reshape(1, -1).astype('float32')
            faiss.normalize_L2(target_vec)
            
            # Search (L·∫•y top_k + 1 v√¨ k·∫øt qu·∫£ ƒë·∫ßu ti√™n l√† ch√≠nh n√≥)
            D, I = self.index.search(target_vec, top_k + 1)
            
            # B·ªè qua k·∫øt qu·∫£ ƒë·∫ßu ti√™n (ch√≠nh n√≥)
            related_indices = I[0][1:]
            related_products = self.df.iloc[related_indices].copy()
            related_products['score'] = D[0][1:]
            
            return related_products
        except:
            return None

engine = ShopSearchEngine(df, bm25, index, sbert_model, embeddings)

# ============================================
# 5. QU·∫¢N L√ù TR·∫†NG TH√ÅI (SESSION STATE)
# ============================================
if 'selected_product_id' not in st.session_state:
    st.session_state.selected_product_id = None

def view_product(aid):
    st.session_state.selected_product_id = str(aid)

def back_to_search():
    st.session_state.selected_product_id = None

# Helper ƒë·ªÉ l·∫•y ƒë∆∞·ªùng d·∫´n ·∫£nh
def get_img_path(aid):
    aid_str = str(aid).zfill(10)
    path = os.path.join(LOCAL_IMG_DIR, f"{aid_str}.jpg")
    if os.path.exists(path):
        return path
    return "https://via.placeholder.com/300x400.png?text=No+Image"

# ============================================
# 6. GIAO DI·ªÜN CH√çNH (UI)
# ============================================

# --- M√ÄN H√åNH CHI TI·∫æT S·∫¢N PH·∫®M ---
if st.session_state.selected_product_id:
    aid = st.session_state.selected_product_id
    
    # Header & N√∫t Back
    c_back, c_title = st.columns([1, 5])
    with c_back:
        st.button("‚¨ÖÔ∏è Quay l·∫°i", on_click=back_to_search)
    
    try:
        # L·∫•y th√¥ng tin
        prod = df[df['article_id'].astype(str) == aid].iloc[0]
        
        # Layout 2 c·ªôt: ·∫¢nh - Th√¥ng tin
        c_img, c_info = st.columns([1.5, 3])
        
        with c_img:
            st.image(get_img_path(aid), use_container_width=True)
            
        with c_info:
            st.title(prod['prod_name'])
            st.markdown(f"### ${prod.get('price', 0):.2f}")
            st.write(f"**M√†u s·∫Øc:** {prod.get('colour_group_name', 'N/A')}")
            st.write(f"**Danh m·ª•c:** {prod.get('product_type_name', 'N/A')}")
            st.info(prod.get('detail_desc', 'Ch∆∞a c√≥ m√¥ t·∫£ chi ti·∫øt.'))
            st.button("üõí Th√™m v√†o gi·ªè h√†ng", key="add_to_cart")
            st.caption(f"ID: {aid}")

        st.divider()
        st.subheader("üîç S·∫£n ph·∫©m t∆∞∆°ng t·ª± (C√≥ th·ªÉ b·∫°n s·∫Ω th√≠ch)")
        
        # Ph·∫ßn Recommendation
        related = engine.get_related_products(aid, top_k=5)
        if related is not None:
            cols = st.columns(5)
            for idx, (i, row) in enumerate(related.iterrows()):
                r_aid = str(row['article_id']).zfill(10)
                with cols[idx]:
                    st.image(get_img_path(r_aid), use_container_width=True)
                    st.caption(f"{row['prod_name'][:20]}...")
                    # N√∫t xem ti·∫øp
                    st.button("Xem", key=f"rec_{r_aid}", on_click=view_product, args=(r_aid,))
                    
    except Exception as e:
        st.error("Kh√¥ng t√¨m th·∫•y th√¥ng tin s·∫£n ph·∫©m.")
        if st.button("Reset"): back_to_search()

# --- M√ÄN H√åNH T√åM KI·∫æM (TRANG CH·ª¶) ---
else:
    st.title("H&M AI Fashion Search")
    st.caption("T√¨m ki·∫øm th√¥ng minh v·ªõi Hybrid Search & Recommendation")
    
    # Sidebar Config
    with st.sidebar:
        st.header(" B·ªô l·ªçc")
        alpha = st.slider("Alpha (Semantic vs Keyword)", 0.0, 1.0, 0.5)
        top_k = st.slider("S·ªë k·∫øt qu·∫£ hi·ªÉn th·ªã", 5, 20, 10)
        st.markdown("---")
        st.info(" Th·ª≠ t√¨m: 'Black running shoes', 'Floral summer dress'...")

    # Search Box
    c_input, c_btn = st.columns([4, 1])
    with c_input:
        query = st.text_input("B·∫°n ƒëang t√¨m g√¨?", placeholder="M√¥ t·∫£ s·∫£n ph·∫©m...", key="search_box")
    with c_btn:
        st.write("")
        st.write("")
        do_search = st.button("üîç T√¨m ki·∫øm")

    if do_search or query:
        with st.spinner("AI ƒëang t√¨m ki·∫øm..."):
            results, expanded_q = engine.search(query, top_k=top_k, alpha=alpha)
        
        # # Debug Info
        # with st.expander("üïµÔ∏è‚Äç‚ôÇÔ∏è Xem c∆° ch·∫ø AI (Debug)"):
        #     st.write(f"**Query g·ªëc:** {query}")
        #     if query.lower() != expanded_q:
        #         st.success(f"**Expanded:** {expanded_q}")
        #     else:
        #         st.info("Query gi·ªØ nguy√™n.")

        st.markdown(f"### T√¨m th·∫•y {len(results)} k·∫øt qu·∫£ ph√π h·ª£p")
        
        # V√≤ng l·∫∑p hi·ªÉn th·ªã k·∫øt qu·∫£
        for idx, row in results.iterrows():
            with st.container():
                c1, c2, c3 = st.columns([1.5, 4.5, 1.5])
                
                # L·∫•y ID an to√†n
                raw_id = row.get('article_id', idx)
                aid_str = str(raw_id).zfill(10)
                
                with c1:
                    st.image(get_img_path(aid_str), width=150)
                
                with c2:
                    st.subheader(row.get('prod_name', 'Unknown'))
                    st.write(f"**Gi√°:** ${row.get('price', 0):.2f}")
                    desc = str(row.get('detail_desc', ''))
                    st.write(desc[:200] + "..." if len(desc) > 200 else desc)
                    st.caption(f"ID: {aid_str}")
                
                with c3:
                    score = row.get('score', 0)
                    st.metric("Match Score", f"{score:.2f}")
                    # N√∫t Xem Chi Ti·∫øt -> G·ªçi h√†m chuy·ªÉn view
                    st.button("Xem chi ti·∫øt", key=f"main_{aid_str}", on_click=view_product, args=(aid_str,))
            
            st.divider()